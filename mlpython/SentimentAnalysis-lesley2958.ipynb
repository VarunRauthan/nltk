{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/lesley2958/machine-learning-series-python#30-sentiment-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def format_sentence(sent):\n",
    "    return({word: True for word in nltk.word_tokenize(sent)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = []\n",
    "with open(\"./data/pos_tweets.txt\") as f:\n",
    "    for i in f: \n",
    "        pos.append([format_sentence(i), 'pos'])\n",
    "pos[1]\n",
    "with open(\"./data/pos.txt\") as f:\n",
    "    for i in f: \n",
    "        pos.append([format_sentence(i), 'pos'])\n",
    "dirname=\"./data/aclImdb_v1/train/pos/\"\n",
    "import os\n",
    "for fname in os.listdir(dirname):\n",
    "    with open(os.path.join(dirname, fname), 'r') as f:\n",
    "        for i in f: \n",
    "            pos.append([format_sentence(i), 'pos'])\n",
    "dirname1=\"./data/aclImdb_v1/test/pos/\"\n",
    "import os\n",
    "for fname in os.listdir(dirname1):\n",
    "    with open(os.path.join(dirname1, fname), 'r') as f:\n",
    "        for i in f: \n",
    "            pos.append([format_sentence(i), 'pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = []\n",
    "with open(\"./data/neg_tweets.txt\") as f:\n",
    "    for i in f: \n",
    "        neg.append([format_sentence(i), 'neg'])\n",
    "with open(\"./data/neg.txt\") as f:\n",
    "    for i in f: \n",
    "        neg.append([format_sentence(i), 'neg'])\n",
    "dirname=\"./data/aclImdb_v1/train/neg/\"\n",
    "import os\n",
    "for fname in os.listdir(dirname):\n",
    "    with open(os.path.join(dirname, fname), 'r') as f:\n",
    "        for i in f: \n",
    "            neg.append([format_sentence(i), 'neg'])\n",
    "dirname1=\"./data/aclImdb_v1/test/neg/\"\n",
    "import os\n",
    "for fname in os.listdir(dirname1):\n",
    "    with open(os.path.join(dirname1, fname), 'r') as f:\n",
    "        for i in f: \n",
    "            neg.append([format_sentence(i), 'neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pos[:int((.9)*len(pos))] + neg[:int((.9)*len(neg))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pos[int((.1)*len(pos)):] + neg[int((.1)*len(neg)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    3/10 = True              neg : pos    =    140.0 : 1.0\n",
      "                   Avoid = True              neg : pos    =    135.7 : 1.0\n",
      "                    2/10 = True              neg : pos    =    105.6 : 1.0\n",
      "                    *1/2 = True              neg : pos    =     74.9 : 1.0\n",
      "                    Boll = True              neg : pos    =     41.5 : 1.0\n",
      "                     Uwe = True              neg : pos    =     40.5 : 1.0\n",
      "                   WORST = True              neg : pos    =     37.6 : 1.0\n",
      "                    4/10 = True              neg : pos    =     37.3 : 1.0\n",
      "                  awful. = True              neg : pos    =     32.5 : 1.0\n",
      "                    1/10 = True              neg : pos    =     30.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg\n"
     ]
    }
   ],
   "source": [
    "example1 = \"efficiency, politeness, unexpected discount on next transaction.  \"\n",
    "\n",
    "print(classifier.classify(format_sentence(example1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg\n"
     ]
    }
   ],
   "source": [
    "example2 = \"this workshop is awful.\"\n",
    "\n",
    "print(classifier.classify(format_sentence(example2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9280995300474493\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify.util import accuracy\n",
    "print(accuracy(classifier, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#list_pickle = pickle.dumps(classifier)\n",
    "\n",
    "#loaded_pickle = pickle.loads(list_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_pickle = pickle.loads(list_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open ('./data/chk.txt', 'ab') as f: f.write(list_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"./data/chk.txt\", \"rb\") as f:\n",
    " #   byte = f.read(1)\n",
    "  #  while byte != \"\":\n",
    "   #     # Do stuff with byte.\n",
    "    #    byte = f.read(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/SentimentAnalysis-lesley2958.pickle', 'wb') as file:\n",
    "    pickle.dump(classifier, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/SentimentAnalysis-lesley2958.pickle' ,'rb') as f:\n",
    "    loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Making excuses...  : neg\n"
     ]
    }
   ],
   "source": [
    "print(\" Making excuses...  :\",  loaded_model.classify(format_sentence(\" Making excuses... \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You held back the transaction until you spoke with me because you were concerned it was a scam and you were right. Thank you  : neg\n"
     ]
    }
   ],
   "source": [
    "print(\" You held back the transaction until you spoke with me because you were concerned it was a scam and you were right. Thank you  :\",  classifier.classify(format_sentence(\" You held back the transaction until you spoke with me because you were concerned it was a scam and you were right. Thank you \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Agent understood my problem, and explained how we could correct it.  : neg\n"
     ]
    }
   ],
   "source": [
    "print(\" Agent understood my problem, and explained how we could correct it.  :\",  classifier.classify(format_sentence(\" Agent understood my problem, and explained how we could correct it. \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " After chatting I understand what is going on.  : neg\n"
     ]
    }
   ],
   "source": [
    "print(\" After chatting I understand what is going on.  :\",  classifier.classify(format_sentence(\" After chatting I understand what is going on. \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Awesome conducting business online instead of having to wait in long line!  : pos\n"
     ]
    }
   ],
   "source": [
    "print(\" Awesome conducting business online instead of having to wait in long line!  :\",  classifier.classify(format_sentence(\" Awesome conducting business online instead of having to wait in long line \")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the person to whom i spoke to was very sweet and friendly.  : pos\n"
     ]
    }
   ],
   "source": [
    "print(\" the person to whom i spoke to was very sweet and friendly.  :\",  classifier.classify(format_sentence(\" the person to whom i spoke to was very sweet and friendly. \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Prompt service.  : neg\n"
     ]
    }
   ],
   "source": [
    "print(\" Prompt service.  :\",  classifier.classify(format_sentence(\" Prompt service. \")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " She did her best to assist me  : pos\n"
     ]
    }
   ],
   "source": [
    "print(\" She did her best to assist me  :\",  classifier.classify(format_sentence(\" She did her best to assist me \")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Efficiency, politeness, unexpected discount on next transaction.  : neg\n"
     ]
    }
   ],
   "source": [
    "print(\" Efficiency, politeness, unexpected discount on next transaction.  :\",  classifier.classify(format_sentence(\" Efficiency, politeness, unexpected discount on next transaction. \")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dont remember  : neg\n"
     ]
    }
   ],
   "source": [
    "print(\" dont remember  :\",  classifier.classify(format_sentence(\" dont remember. \")))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
